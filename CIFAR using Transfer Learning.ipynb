{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from IPython.display import Image,display\n",
    "import prettytensor as pt ## For simplifying neuralnetwork representation\n",
    "import inception  ### A python file in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cifar10 ## MOdule in the directory\n",
    "from cifar10 import num_classes\n",
    "cifar10.data_path = \"data/CIFAR-10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10.maybe_download_and_extract() ### A function in cifar10 module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = cifar10.load_class_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names ## Names in cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, cls_train, labels_train = cifar10.load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test, cls_test, labels_test = cifar10.load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of--\")\n",
    "print(\"Training Data \\t\\t{}\".format(len(images_train)))\n",
    "print(\"Test Data \\t\\t{}\".format(len(images_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None, smooth=True):\n",
    "    \n",
    "    assert len(images)==len(cls_true)\n",
    "    \n",
    "    fig, axes = plt.subplots(3,3)\n",
    "    \n",
    "    if cls_pred is None:\n",
    "        hspace = 0.3\n",
    "    else:\n",
    "        hspace = 0.6 ## More hspace to represent since we need to represnt both cls_pred and cls_true\n",
    "    \n",
    "    if smooth is True:\n",
    "        interpolation = \"spline16\"  \n",
    "    else:\n",
    "        interpolation = \"nearest\"\n",
    "        \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        \n",
    "        if i<len(images):  ### VIMP---> in case images are less than 9\n",
    "            ax.imshow(images[i], interpolation=interpolation)  ## Each ax is drawn\n",
    "        \n",
    "            cls_true_name = class_names[cls_true[i]]\n",
    "            \n",
    "            if cls_pred is None: ## Only 1 thing to represent\n",
    "                xlabel = \"True:{0}\".format(cls_true_name)\n",
    "            else:   ## 2 things two represent\n",
    "                cls_pred_name = class_names[cls_pred[i]]\n",
    "                xlabel = \"True:{0}\\nPredicted:{1}\".format(cls_true_name,cls_pred_name)\n",
    "        \n",
    "            ax.set_xlabel(xlabel) \n",
    "        \n",
    "        ax.set_xticks([]) ### Remove xticks from plot\n",
    "        ax.set_yticks([]) ### Remove yticks from plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Show some images\n",
    "images = images_train[0:9]\n",
    "\n",
    "cls_true = cls_train[0:9]\n",
    "\n",
    "plot_images(images,cls_true,cls_pred=None,smooth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.data_dir = 'inception/' ##Directory would be created if not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.maybe_download() ## It would be downlaode if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inception.Inception() ## Model is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inception Model----> We will not train our Inception Model on Cifar10 dataset. Instead we are using the same trained \n",
    "## Inception model and altering our output wrt to Cifar10\n",
    "## Our last layer is called transfer layer and its output is transfer values which we will store in cache files so as to ease \n",
    "## the access. Now all these transfer values are inputted to another neural network(II). Whose final layer is a softmax layer \n",
    "## with 10outputs for each of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inception import transfer_values_cache ## A function to convert transfer values to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File to store cache \n",
    "file_path_cache_train = os.path.join(cifar10.data_path,'inception_cifar10_train.pkl')\n",
    "file_path_cache_test = os.path.join(cifar10.data_path, 'inception_cifar10_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing Transfer values for training Images--->\")\n",
    "### Images are scaled since cifar10 is returning pixel between 1 and 10 and we need in between 0 and 255\n",
    "images_scaled = images_train*255.0\n",
    "\n",
    "transfer_values_train = transfer_values_cache(cache_path=file_path_cache_train,\n",
    "                                             images=images_scaled,\n",
    "                                             model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing Transfer values for testing images--->\")\n",
    "\n",
    "images_scaled = images_train * 255.0\n",
    "\n",
    "transfer_values_test = transfer_values_cache(cache_path = file_path_cache_test,\n",
    "                                            images = images_scaled,\n",
    "                                            model = model)\n",
    "\n",
    "## We are calculating transfer values and saving them as cache on the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values_train.shape\n",
    "## Shape is (50000,2048) i.e. each images has an array 0f 2048 elements which are basically output from transfer value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values_test.shape\n",
    "## Shape is (10000,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to plot transfer values for test\n",
    "def plot_transfer_values(i):\n",
    "    print(\"Input Image:\")\n",
    "    \n",
    "    plt.imshow(images_test[i],interpolation='nearest') ## Plots input test image 32*32 pixel hence pixelated\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Transfer values for image using Inception Model:\")\n",
    "    img = transfer_values_test[i]\n",
    "    img = img.reshape((32,64))\n",
    "    plt.imshow(img,interpolation='nearest',cmap'Reds') ##cmap-color map image plotted would be of fifferent degrree of red color\n",
    "    plt.show()\n",
    "    \n",
    "## Transfer values are plotted cannot be understood by normal means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we have to analyse transfer values so as to see of inception model is successfull to sepearte usefull information and \n",
    "## seperate classes. But transfer values have 2048 and hence difficult to plot \n",
    "## Hence we do dimensionality reduction is applied\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2) ## N0componets decide to which level to be dropped\n",
    "\n",
    "transfer_values = transfer_values_train[0:3000] ## Only reducing first 3000 images since takes a lot of time to convert\n",
    "\n",
    "cls = cls_train[0:3000]\n",
    "\n",
    "transfer_values.shape ## Right now shape is 3000,2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values_reduced = pca.fit_transform(transfer_values)\n",
    "\n",
    "transfer_values_reduced.shape ## Shape is 3000,2  Shape is reuced to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(values,cls):\n",
    "    \n",
    "    import matplotlib.cm as cm\n",
    "    ## By this we can define our own colormap differnet for each class[10 classes]\n",
    "    cmap = cm.rainbow(np.linspace(0.0,1.0,num_classes))\n",
    "    ## Color map created np.linspace defines equally spced 10 numbers between 0 to 1\n",
    "    colors = cmap[cls] ## get color for each cls\n",
    "    x = values[:,0] ## First value\n",
    "    y = values[:,1]  ## Second value\n",
    "    \n",
    "    plt.scatter(x,y,colors=colors) ## Scatter plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(transfer_values_reduced,cls) ## Plotting reduce dtransfer values\n",
    "## Values have been plotted and though there have been seperation of classes but still there is large large overlapping of \n",
    "## classes which can be due to several resaons---maybe PCA is not able to reduce 2048 to 2 or maybe Incetion model is not able \n",
    "## to differentiate between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now using a more advanced technique--> t-SNE  t-distributed Stochastic Neighbor Embedding\n",
    "## It can effectively reduce high diensions into saller with a preconditionthat initiall another dimensionalyt reduction has\n",
    "## to be applied first\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "pca = PCA(n_components=50) ## pca applied and reuce dimension to 50\n",
    "transfer_values50d = pca.fit_transform(transfer_values) ## now dimensions are 3000,50\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "transfer_values_reduced = tsne.fit_transform(transfer_values50d)\n",
    "\n",
    "transfer_values_reduced.shape ## Shape is 3000,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(transfer_values_reduced,cls) ## Now plot show much better sepearated clusters which tells us that transfer values\n",
    "## can indeed be used to seperate between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now since transfer values are capable of seperating classes\n",
    "## We need to construct a neural network that takes transfer values as input and output class numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_len = model.transfer_len ## Array length of transfer values=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape = [None,transfer_len],name='x') ## None represent no of images which will be inputted\n",
    "                                                                    \n",
    "y_true = tf.placeholder(tf.float32, shape = [None,num_classes], name='y_true') ## true labels that are inputted\n",
    "\n",
    "y_true_cls = tf.argmax(y_true,axis=1) ## True classes in int form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Neural Network using pretty tensor\n",
    "x_pretty = pt.wrap(x)\n",
    "\n",
    "with pt.defaults_scope(activation_fn=tf.nn.relu):  ## i.e BY default all ndes have relu activation function\n",
    "    y_pred,loss = x_pretty.\\ ## IMP----> output is y_pred & loss\n",
    "        fully_connected(size=1024,name='layer_fc1').\\\n",
    "        softmax_classifier(num_classes=num_classes,labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(initial_value=50,\n",
    "                         name='global_step',trainable=False) ## It means during optimization this will not train\n",
    "## This is used only as a step counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss,global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred,axis=1) ## y_pred is in hot encode form this will be now in int form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls,y_true_cls)  ## This will yield a boolean array\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) \n",
    "### IMP--> reduce_mean basically calculates average tf.cas boolean array into float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session  = tf.Session() ## Creates a tensorflow session\n",
    "session.run(tf.global_variables_initializer()) ## Variables initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WE will be using batch gradient descent i.e instead of going thro' all the examples in trainig data\n",
    "## to make one gradient descent step we will make a step once going thro' a batch of training data\n",
    "\n",
    "train_batch_size = 64\n",
    "\n",
    "def random_batch():\n",
    "    num_images = len(transfer_values_train) ## IMP---> Transfer balues are input \n",
    "    \n",
    "    idx = np.random.choice(num_images,\n",
    "                          size = train_batch_size,  ## Out of total images how manny images has to be chosen randomly\n",
    "                          replace = False) ## This means same image will not repeated\n",
    "    x_batch = transfer_values_train[idx]\n",
    "    y_batch = labels_train[idx]\n",
    "    \n",
    "    return x_batch,y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(num_iterations):\n",
    "    \n",
    "    start_time = time.time() ###For time usage\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        x_batch, y_true_batch = random_batch()\n",
    "        \n",
    "        feed_dict_train = { x : x_batch, y_true : y_true_batch}\n",
    "        \n",
    "        i_global,_ = session.run([global_step,optimizer],feed_dict=feed_dict_train)\n",
    "        ### we are running global_step also since we need global step counter i.e i+global\n",
    "        \n",
    "        if (i_global %100==0) or (i ==num_iterations-1):\n",
    "            \n",
    "            batch_acc = session.run(accuracy,feed_dict=feed_dict_train)\n",
    "            ## Accuracy tensorflow graph is run and it's batch accuracy is stored in batch_acc\n",
    "            msg = \"Global Step: {0:>6}, Training Batch Accuracy: {1:>6.1%}\"\n",
    "            print(msg.format(i_global, batch_acc))\n",
    "            \n",
    "    end_time = time.time()\n",
    "    \n",
    "    time_dif = end_time - start_time\n",
    "    \n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_errors(cls_pred, correct):\n",
    "    \n",
    "    incorrect = (correct == False) ### Negate the boolean array\n",
    "    \n",
    "    images = images_test[incorrect] ## Images of test set that have been incorrectly classified\n",
    "    cls_pred = cls_pred[incorrect]  ## Predicted classes of incorrectly classified images\n",
    "    cls_true = cls_test[incorrect] ## True classes of incorrectly classified images\n",
    "    n = min(9,len(images))\n",
    "    ## Using abve function to plot first n images\n",
    "    plot_images(images=images[0:n],cls_true=cls_true[0:n],cls_pred=cls_pred[0:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cls_pred):\n",
    "    \n",
    "    cm = confusion_matrix(y_true = cls_test,\n",
    "                         y_pred = cls_pred)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        \n",
    "        class_name = \"({}) {}\".format(i,class_names[i])\n",
    "        print(cm[i,:],class_name)\n",
    "        \n",
    "    class_numbers = [\" ({0})\".format(i) for i in range(num_classes)]\n",
    "    print(\"\".join(class_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "def predict_cls(transfer_values, labels, cls_true):\n",
    "    num_images = len(transfer_values)\n",
    "    \n",
    "    cls_pred = np.zeros(shape=num_images, dtype=np.int)\n",
    "    i = 0\n",
    "\n",
    "    while i < num_images:\n",
    "        j = min(i + batch_size, num_images)\n",
    "        \n",
    "        feed_dict = {x: transfer_values[i:j],\n",
    "                     y_true: labels[i:j]}\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "        i = j\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "    \n",
    "    return correct, cls_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cls_test():\n",
    "    return predict_cls(transfer_values = transfer_values_test, ##VIMP---> pass transfer values\n",
    "                       labels = labels_test,\n",
    "                       cls_true = cls_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(correct): ## Correct is aboolean array\n",
    "    return correct.mean(), correct.sum() ## Mean is basically accuracy only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fucntion for printing test accuracy\n",
    "def print_test_accuracy(show_example_errors=False,\n",
    "                        show_confusion_matrix=False):\n",
    "\n",
    "    correct, cls_pred = predict_cls_test()\n",
    "    \n",
    "    # Classification accuracy and the number of correct classifications.\n",
    "    acc, num_correct = classification_accuracy(correct)\n",
    "    \n",
    "    # Number of images being classified.\n",
    "    num_images = len(correct) ## VIMP---> This show total images coorect as wella sincorrect\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, num_correct, num_images))\n",
    "\n",
    "    # Plot some examples of mis-classifications, if desired.\n",
    "    if show_example_errors:\n",
    "        print(\"Example errors:\")\n",
    "        plot_example_errors(cls_pred=cls_pred, correct=correct)\n",
    "\n",
    "    # Plot the confusion matrix, if desired.\n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        plot_confusion_matrix(cls_pred=cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(num_iterations = 10000) ## Num of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_accuracy(show_example_errors=True,show_confusion_matrix=True)\n",
    "## This will plot some images that are incorreclty misclassified and confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Giving an accuracy of-------> \"\"90.7%\"\" at 10000 iterations as compared to using normal convolutional neural networks \n",
    "### which gives only 80%at 15000 iterations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
