{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST using Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import prettytensor as pt ### Pretty tensor used to simplify NN representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/',one_hot=True) ## data in HOT encoding form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of-->\n",
      "Training Set:-\t\t55000\n",
      "Test Set:-\t\t10000\n",
      "Validation Set:-\t5000\n"
     ]
    }
   ],
   "source": [
    "print('Size of-->')\n",
    "print(\"Training Set:-\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"Test Set:-\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"Validation Set:-\\t{}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test.cls =  np.argmax(data.test.labels,axis=1)\n",
    "data.validation.cls  = np.argmax(data.validation.labels,axis=1) ## axis=1 means horizontal direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Traing set and Validation combined for ensemble\n",
    "combined_images = np.concatenate([data.train.images,data.validation.images],axis=0)\n",
    "combined_labels = np.concatenate([data.train.labels,data.validation.labels],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_size = len(combined_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.8*combined_size)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Learning ---> It includes developing neural networks from random traing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating random training set\n",
    "\n",
    "def random_training_set():\n",
    "    \n",
    "    idx = np.random.permutation(combined_size) ##Creates a random permutation array Eg- np.random.permutation(5)\n",
    "    ## can create 5 3 2 4 1 or 1 4 2 5 3 and many more\n",
    "    \n",
    "    idx_train = idx[0:train_size]\n",
    "    idx_validation = idx[train_size:]\n",
    "    \n",
    "    x_train = combined_images[idx_train,:]\n",
    "    y_train = combined_labels[idx_train,:]\n",
    "    \n",
    "    x_validation  = combined_images[idx_validation,:]\n",
    "    y_validation = combined_labels[idx_validation,:]\n",
    "    \n",
    "    return x_train,y_train,x_validation,y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "img_shape = (img_size, img_size)\n",
    "num_channels = 1\n",
    "\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images,                  \n",
    "                cls_true,                \n",
    "                ensemble_cls_pred=None,  \n",
    "                best_cls_pred=None):     \n",
    "\n",
    "    assert len(images) == len(cls_true)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    if ensemble_cls_pred is None:\n",
    "        hspace = 0.3\n",
    "    else:\n",
    "        hspace = 1.0\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(images):\n",
    "            # Plot image.\n",
    "            ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "            if ensemble_cls_pred is None:\n",
    "                xlabel = \"True: {0}\".format(cls_true[i])\n",
    "            else:\n",
    "                msg = \"True: {0}\\nEnsemble: {1}\\nBest Net: {2}\"\n",
    "                xlabel = msg.format(cls_true[i],\n",
    "                                    ensemble_cls_pred[i],\n",
    "                                    best_cls_pred[i])\n",
    "            ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,img_size_flat],name='x')\n",
    "\n",
    "## VV IMP--> Tensorfloe expects convolution layers to be encoded in 4 dim tensor [Num_images,img_height,img_weight,num_channels]\n",
    "x_image = tf.reshape(x,[-1,img_size,img_size,num_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32,shape=[None,10],name='y')\n",
    "\n",
    "y_true_cls = tf.argmax(y_true,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pretty = pt.wrap(x_image)  ## preety rensor wrapped around our x to create a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pt.defaults_scope(activation_fn=tf.nn.relu):  ## Now default is relu activation  ##y_pred is in HOT encoded form## depth is --> no of filters\n",
    "    y_pred,loss = x_pretty.conv2d(kernel=5,depth=16,name='layer_conv1').max_pool(kernel=2,stride=2).\\\n",
    "        conv2d(kernel=5,depth=36,name='layer_conv2').\\\n",
    "        max_pool(kernel=2,stride=2).\\\n",
    "        flatten().\\\n",
    "        fully_connected(size=128,name='layer_fc1').\\\n",
    "        softmax_classifier(num_classes=num_classes,labels=y_true)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_true_cls,y_pred_cls)  ## A vector of booleans\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))  ## reduce_mean is average and bool is casted to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "save_dir = 'checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_path(net_number):\n",
    "    return save_dir + 'network' + str(net_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "def init_variables():\n",
    "    session.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "\n",
    "def random_batch(x_train, y_train):\n",
    "    num_images = len(x_train)\n",
    "\n",
    "    idx = np.random.choice(num_images, size=train_batch_size, replace=False)\n",
    "    \n",
    "    x_batch = x_train[idx, :]  # Images.\n",
    "    y_batch = y_train[idx, :]  # Labels.\n",
    "\n",
    "    # Return the batch.\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(num_iterations, x_train, y_train):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        x_batch, y_true_batch = random_batch(x_train, y_train)\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            \n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Batch Accuracy: {1:>6.1%}\"\n",
    "\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_networks = 5\n",
    "\n",
    "num_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network: 0\n",
      "Optimization Iteration:      1, Training Batch Accuracy:  14.1%\n",
      "Optimization Iteration:    101, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:    201, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:    301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:    401, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:    501, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:    601, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:    701, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:    801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:    901, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   1001, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   1101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   1201, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   1301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   1401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1501, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   1601, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1701, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1801, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   1901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2001, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   2101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2301, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   2401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2901, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3101, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3201, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   3301, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6401, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   6501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   8301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   9201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   9301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9901, Training Batch Accuracy: 100.0%\n",
      "Time usage: 0:24:40\n",
      "\n",
      "Neural network: 1\n",
      "Optimization Iteration:      1, Training Batch Accuracy:   9.4%\n",
      "Optimization Iteration:    101, Training Batch Accuracy:  89.1%\n",
      "Optimization Iteration:    201, Training Batch Accuracy:  82.8%\n",
      "Optimization Iteration:    301, Training Batch Accuracy:  89.1%\n",
      "Optimization Iteration:    401, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:    501, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:    601, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:    701, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:    801, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:    901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1001, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1301, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   1501, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:   1601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   1701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1901, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2101, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2201, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2701, Training Batch Accuracy:  95.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   2801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3801, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4701, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   4801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6701, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   6801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8901, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   9001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   9201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   9801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9901, Training Batch Accuracy:  98.4%\n",
      "Time usage: 0:24:46\n",
      "\n",
      "Neural network: 2\n",
      "Optimization Iteration:      1, Training Batch Accuracy:   6.2%\n",
      "Optimization Iteration:    101, Training Batch Accuracy:  75.0%\n",
      "Optimization Iteration:    201, Training Batch Accuracy:  89.1%\n",
      "Optimization Iteration:    301, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:    401, Training Batch Accuracy:  85.9%\n",
      "Optimization Iteration:    501, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:    601, Training Batch Accuracy:  89.1%\n",
      "Optimization Iteration:    701, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:    801, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:    901, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   1001, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   1101, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   1201, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   1301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1401, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1501, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   1601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   1701, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1801, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   1901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2001, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   2101, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2201, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2301, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2901, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:   3001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3301, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3801, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4801, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   4901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5001, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   5101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5401, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   5501, Training Batch Accuracy: 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   5601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6001, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   6101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6301, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   6401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6901, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   7001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   8101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   8401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   9001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   9501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   9701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9901, Training Batch Accuracy: 100.0%\n",
      "Time usage: 0:24:52\n",
      "\n",
      "Neural network: 3\n",
      "Optimization Iteration:      1, Training Batch Accuracy:  14.1%\n",
      "Optimization Iteration:    101, Training Batch Accuracy:  82.8%\n",
      "Optimization Iteration:    201, Training Batch Accuracy:  89.1%\n",
      "Optimization Iteration:    301, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:    401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:    501, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:    601, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:    701, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:    801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:    901, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1101, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   1201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   1601, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1701, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   1901, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2301, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2501, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   2601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2701, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   2801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3501, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   3601, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4701, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   4801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4901, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   5001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6701, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   6801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8001, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   8101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8301, Training Batch Accuracy:  98.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   8401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   8801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   9201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   9801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9901, Training Batch Accuracy: 100.0%\n",
      "Time usage: 0:23:03\n",
      "\n",
      "Neural network: 4\n",
      "Optimization Iteration:      1, Training Batch Accuracy:   7.8%\n",
      "Optimization Iteration:    101, Training Batch Accuracy:  89.1%\n",
      "Optimization Iteration:    201, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:    301, Training Batch Accuracy:  87.5%\n",
      "Optimization Iteration:    401, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:    501, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:    601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:    701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:    801, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:    901, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   1001, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   1101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   1401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1501, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   1601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   1801, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   1901, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   2001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2401, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   2501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   2601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   2801, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:   2901, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3301, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3401, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   3501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   3701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   3901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   4701, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:   4801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   4901, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:   5001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   5801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   5901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6201, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   6601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   6901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7301, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   7401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   7901, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8001, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8101, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8401, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8801, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   8901, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   9001, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   9101, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   9201, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9301, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9401, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   9501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9601, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   9701, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:   9801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:   9901, Training Batch Accuracy: 100.0%\n",
      "Time usage: 0:17:28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    for i in range(num_networks):\n",
    "        print(\"Neural network: {0}\".format(i))\n",
    "\n",
    "        x_train, y_train, _, _ = random_training_set()\n",
    "\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        optimize(num_iterations=num_iterations,\n",
    "                 x_train=x_train,\n",
    "                 y_train=y_train)\n",
    "\n",
    "        saver.save(sess=session, save_path=get_save_path(i))\n",
    "\n",
    "        # Print newline.\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting Test data into batches and finding labels\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "def predict_labels(images):\n",
    "    num_images = len(images) ###images is the test data\n",
    "    ##num_images now represent no of images in test dataset\n",
    "    \n",
    "    pred_label  = np.zeros(shape=(num_images,num_classes),dtype = np.float)\n",
    "    ## i.e now we have defined an arrayof zeros of the above shape\n",
    "    \n",
    "    \n",
    "    i = 0 ## this represents starting index of next batch\n",
    "    \n",
    "    while i < num_images:\n",
    "        \n",
    "        j = min(i + batch_size, num_images) ###In case i exceeds number of images\n",
    "        \n",
    "        feed_dict = {x: images[i:j,:]} ### Values to be fed\n",
    "        \n",
    "        pred_label[i:j] = session.run(y_pred,feed_dict = feed_dict)## running y_pred i.e NN and feeding thro dict\n",
    "        \n",
    "        i=j\n",
    "        \n",
    "    return pred_label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_prediction(images, labels, cls_true):\n",
    "    \n",
    "    pred_labels = predict_labels(images=images)  ##i.e using above defined function\n",
    "    \n",
    "    cls_pred = np.argmax(pred_labels,axis=1) \n",
    "    \n",
    "    correct = (cls_true==cls_pred)  ### Creates a boolean array\n",
    "    \n",
    "    return correct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Boolean array for test data\n",
    "\n",
    "def test_correct():\n",
    "    return correct_prediction(images=data.test.images, labels = data.test.labels, cls_true=data.test.cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Boolean array for validation data\n",
    "\n",
    "def validation_correct():\n",
    "    return correct_prediction(images=data.validation.images,\n",
    "                             labels = data.validation.labels,\n",
    "                             cls_true = data.validation.cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(correct): ##correctis boolean array\n",
    "    return correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For test data\n",
    "def test_accuracy():\n",
    "    correct = test_correct()\n",
    "    return classification_accuracy(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For Validation data\n",
    "def validation_accuracy():\n",
    "    correct = validation_correct()\n",
    "    return classification_accuracy(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predictions():\n",
    "    \n",
    "    pred_labels = [] ### Will store labels from all 5 NN\n",
    "    \n",
    "    test_accuracies = [] ## Will store test set accuracy from all 5 NN\n",
    "    \n",
    "    validation_accuracies = [] ## Will store validation set acuuracy from all 5 NN\n",
    "    \n",
    "    for i in range(num_networks):\n",
    "        \n",
    "        saver.restore(sess=session, save_path=get_save_path(i))\n",
    "        \n",
    "        test_acc = test_accuracy()\n",
    "        \n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        val_acc = validation_accuracy()\n",
    "        \n",
    "        validation_accuracies.append(val_acc)\n",
    "        \n",
    "        msg = \"Neural Network : {0}, Validation Set accuracy : {1:.4f}, Test Set accuracy : {2:.4f}\"\n",
    "        print(msg.format(i,val_acc,test_acc))\n",
    "        \n",
    "        pred = predict_labels(images=data.test.images)\n",
    "        \n",
    "        pred_labels.append(pred)\n",
    "        \n",
    "    return np.array(pred_labels), np.array(test_accuracies), np.array(validation_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/network0\n",
      "Neural Network : 0, Validation Set accuracy : 0.9946, Test Set accuracy : 0.9893\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/network1\n",
      "Neural Network : 1, Validation Set accuracy : 0.9956, Test Set accuracy : 0.9893\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/network2\n",
      "Neural Network : 2, Validation Set accuracy : 0.9932, Test Set accuracy : 0.9885\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/network3\n",
      "Neural Network : 3, Validation Set accuracy : 0.9948, Test Set accuracy : 0.9877\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/network4\n",
      "Neural Network : 4, Validation Set accuracy : 0.9934, Test Set accuracy : 0.9881\n"
     ]
    }
   ],
   "source": [
    "pred_labels, test_accuracies, validation_accuracies = ensemble_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test-set accuracy: 0.9886\n",
      "Min test-set accuracy:  0.9877\n",
      "Max test-set accuracy:  0.9893\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean test-set accuracy: {0:.4f}\".format(np.mean(test_accuracies)))\n",
    "print(\"Min test-set accuracy:  {0:.4f}\".format(np.min(test_accuracies)))\n",
    "print(\"Max test-set accuracy:  {0:.4f}\".format(np.max(test_accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ensemble\n",
    "\n",
    "ensemble_pred_labels = np.mean(pred_labels, axis=0) ##average of the predicted labels for all the networks in the ensemble\n",
    "##shape (1000,10)\n",
    "\n",
    "ensemble_cls_pred = np.argmax(ensemble_pred_labels, axis=1)\n",
    "###shape (1000,)\n",
    "ensemble_correct = (ensemble_cls_pred == data.test.cls)\n",
    "\n",
    "ensemble_incorrect = np.logical_not(ensemble_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Best NN\n",
    "\n",
    "best_net = np.argmax(test_accuracies)\n",
    "\n",
    "best_net_pred_labels = pred_labels[best_net, :, :]### sine pred_labels shape (5,1000,10)\n",
    "\n",
    "best_net_cls_pred = np.argmax(best_net_pred_labels, axis=1)\n",
    "\n",
    "best_net_correct = (best_net_cls_pred == data.test.cls)\n",
    "\n",
    "best_net_incorrect = np.logical_not(best_net_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9914"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ensemble_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9893"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(best_net_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_better = np.logical_and(best_net_incorrect,\n",
    "                                 ensemble_correct)\n",
    "ensemble_better.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_net_better = np.logical_and(best_net_correct,\n",
    "                                 ensemble_incorrect)\n",
    "best_net_better.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore Ensemble--->99.1% and classifying 32 images correclt in compare with the best NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
